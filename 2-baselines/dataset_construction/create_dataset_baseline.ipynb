{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520ce726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191f3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/mount/studenten/arbeitsdaten-studenten1/semantic-plausibility/plausible-parrots/'\n",
    "CACHE_DIR = PATH + 'cache/'\n",
    "DATA_PATH = PATH + 'datasets_augmented_preprocessed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992d571",
   "metadata": {},
   "source": [
    "## Load all the 6 data splits. Merge pap_train and pep_train, pap_dev and pep_dev, as well as pap_test and pep_test, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2deb13eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mount/studenten/arbeitsdaten-studenten1/semantic-plausibility/plausible-parrots/datasets_augmented_preprocessed/\n",
      "[]\n",
      "['pap_dev_processed_augmented.csv', 'pep_dev_processed.csv', 'pap_test_processed_augmented.csv', 'pep_train_processed.csv', 'pap_train_processed_augmented.csv', 'pep_test_processed.csv']\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['pap_dev_processed_augmented', 'pep_dev_processed', 'pap_test_processed_augmented', 'pep_train_processed', 'pap_train_processed_augmented', 'pep_test_processed'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = {}\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            fn = file.replace('.csv', '')\n",
    "            fp = root + file\n",
    "            dataframes[fn] = pd.read_csv(fp)\n",
    "            \n",
    "print(len(dataframes))\n",
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f3aa3",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cec23b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Event occurs year.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tortoise brings limb.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headliner overpowers function.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>County receives hour.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Traveler acknowledges recognition.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>Wool clip dust.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Rope hook pan.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>Bag contain tree.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>Gorilla bury leaf.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>Sidewalk curb wheels.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4911 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  label\n",
       "0                     Event occurs year.      1\n",
       "1                  Tortoise brings limb.      1\n",
       "2         Headliner overpowers function.      1\n",
       "3                  County receives hour.      0\n",
       "4     Traveler acknowledges recognition.      1\n",
       "...                                  ...    ...\n",
       "2444                     Wool clip dust.      0\n",
       "2445                      Rope hook pan.      1\n",
       "2446                   Bag contain tree.      0\n",
       "2447                  Gorilla bury leaf.      1\n",
       "2448               Sidewalk curb wheels.      1\n",
       "\n",
       "[4911 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pap train\n",
    "pap_train = dataframes['pap_train_processed_augmented']\n",
    "pap_train.drop('original_label', axis=1, inplace=True)\n",
    "pap_train = pap_train[['text', 'label']]\n",
    "\n",
    "# Pep train\n",
    "pep_train = dataframes['pep_train_processed']\n",
    "pep_train = pep_train[['text', 'label']]\n",
    "\n",
    "# Merge Pap train and Pep train\n",
    "train_wikidata = pd.concat([pap_train, pep_train])\n",
    "train_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d9656",
   "metadata": {},
   "source": [
    "### dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ca7405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Method seizes bacterium.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technician visits community.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inclusion expands range.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pencil puts norm.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solution musters team.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Girl slide water.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Plant bury air.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Hand roll plane.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Cup spill water.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Scissors tear paper.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  label\n",
       "0        Method seizes bacterium.      0\n",
       "1    Technician visits community.      1\n",
       "2        Inclusion expands range.      1\n",
       "3               Pencil puts norm.      0\n",
       "4          Solution musters team.      1\n",
       "..                            ...    ...\n",
       "301             Girl slide water.      0\n",
       "302               Plant bury air.      0\n",
       "303              Hand roll plane.      0\n",
       "304              Cup spill water.      1\n",
       "305          Scissors tear paper.      1\n",
       "\n",
       "[614 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pap dev\n",
    "pap_dev = dataframes['pap_dev_processed_augmented']\n",
    "pap_dev.drop('original_label', axis=1, inplace=True)\n",
    "pap_dev = pap_dev[['text', 'label']]\n",
    "\n",
    "# Pep dev\n",
    "pep_dev = dataframes['pep_dev_processed']\n",
    "pep_dev = pep_dev[['text', 'label']]\n",
    "\n",
    "# Merge Pap dev and Pep dev\n",
    "dev_wikidata = pd.concat([pap_dev, pep_dev])\n",
    "dev_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb83f7",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ded115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interpretation construes title.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mask sustains axis.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trader ensures strategy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animator comprises trip.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welfare constructs hundred.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Air peel bush.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Man pull ant.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Hand fasten crab.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Student beat man.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Cup crop pebbles.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  label\n",
       "0    Interpretation construes title.      1\n",
       "1                Mask sustains axis.      0\n",
       "2           Trader ensures strategy.      1\n",
       "3           Animator comprises trip.      1\n",
       "4        Welfare constructs hundred.      0\n",
       "..                               ...    ...\n",
       "302                   Air peel bush.      0\n",
       "303                    Man pull ant.      0\n",
       "304                Hand fasten crab.      1\n",
       "305                Student beat man.      1\n",
       "306                Cup crop pebbles.      0\n",
       "\n",
       "[615 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pap test\n",
    "pap_test = dataframes['pap_test_processed_augmented']\n",
    "pap_test.drop('original_label', axis=1, inplace=True)\n",
    "pap_test = pap_test[['text', 'label']]\n",
    "\n",
    "# Pep test\n",
    "pep_test = dataframes['pep_test_processed']\n",
    "pep_test = pep_test[['text', 'label']]\n",
    "\n",
    "# Merge Pap test and Pep test\n",
    "test_wikidata = pd.concat([pap_test, pep_test])\n",
    "test_wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d441d10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_wikidata['label'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4e2bc",
   "metadata": {},
   "source": [
    "## Load tokenizer and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d15c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large', cache_dir=CACHE_DIR)\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large', cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5ed34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61904ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta-base': 512,\n",
       " 'roberta-large': 512,\n",
       " 'roberta-large-mnli': 512,\n",
       " 'distilroberta-base': 512,\n",
       " 'roberta-base-openai-detector': 512,\n",
       " 'roberta-large-openai-detector': 512}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4279e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_df:pd.core.frame.DataFrame, tokenizer):\n",
    "        \n",
    "    ids = list(range(len(data_df)))\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = data_df['label'].tolist()\n",
    "    \n",
    "    encoded_inputs = tokenizer(\n",
    "        data_df['text'].tolist(),\n",
    "        return_tensors='pt',\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    print(len(ids))\n",
    "    print(encoded_inputs)\n",
    "    print(encoded_inputs['input_ids'].shape)\n",
    "    print(encoded_inputs['attention_mask'].shape)\n",
    "    print(len(labels))\n",
    "    \n",
    "    dataset_dict = {\n",
    "        'id': ids, \n",
    "        'input_ids': encoded_inputs['input_ids'], \n",
    "        'attention_mask': encoded_inputs['attention_mask'], \n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    hf_dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ccb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4911\n",
      "{'input_ids': tensor([[    0, 44879, 11493,  ...,     1,     1,     1],\n",
      "        [    0,   565,  2723,  ...,     1,     1,     1],\n",
      "        [    0, 28873, 17656,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,   387,  1073,  ...,     1,     1,     1],\n",
      "        [    0,   534,   368,  ...,     1,     1,     1],\n",
      "        [    0,   104,   808,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([4911, 512])\n",
      "torch.Size([4911, 512])\n",
      "4911\n",
      "4911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 4911\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_train = create_dataset(train_wikidata, tokenizer)\n",
    "print(len(hf_dataset_train))\n",
    "hf_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d80d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "{'input_ids': tensor([[    0, 47967,   842,  ...,     1,     1,     1],\n",
      "        [    0, 40529, 14932,  ...,     1,     1,     1],\n",
      "        [    0,  1121, 27953,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 21292,  3825,  ...,     1,     1,     1],\n",
      "        [    0,   347,   658,  ...,     1,     1,     1],\n",
      "        [    0, 12645, 45937,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([614, 512])\n",
      "torch.Size([614, 512])\n",
      "614\n",
      "614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 614\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_dev = create_dataset(dev_wikidata, tokenizer)\n",
    "print(len(hf_dataset_dev))\n",
    "hf_dataset_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e78a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n",
      "{'input_ids': tensor([[    0, 26267, 42354,  ...,     1,     1,     1],\n",
      "        [    0, 47661, 29237,  ...,     1,     1,     1],\n",
      "        [    0, 12667,  7292,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 21292,  1769,  ...,     1,     1,     1],\n",
      "        [    0, 43541,  1451,  ...,     1,     1,     1],\n",
      "        [    0,   347,   658,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([615, 512])\n",
      "torch.Size([615, 512])\n",
      "615\n",
      "615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 615\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_test = create_dataset(test_wikidata, tokenizer)\n",
    "print(len(hf_dataset_test))\n",
    "hf_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ee0486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4911\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 614\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 615\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_train_dev_test = DatasetDict(\n",
    "    {\n",
    "        'train': hf_dataset_train,\n",
    "        'dev': hf_dataset_dev,\n",
    "        'test': hf_dataset_test\n",
    "    }\n",
    ")\n",
    "hf_dataset_train_dev_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "931153ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e63efb694504503b12e46cc76ea0c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd6bbf4d7d8480a83f99e394f343bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6c69bc21ad482084262c594d47d9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset_train_dev_test.save_to_disk('./output/dataset_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d99ae",
   "metadata": {},
   "source": [
    "## Create test sets for Pap and Pep individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f998f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interpretation construes title.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mask sustains axis.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trader ensures strategy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animator comprises trip.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welfare constructs hundred.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Majority stops helmet.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Beach picks involvement.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Book realizes size.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Landfill intersects number.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Heat emphasizes opponent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  label\n",
       "0    Interpretation construes title.      1\n",
       "1                Mask sustains axis.      0\n",
       "2           Trader ensures strategy.      1\n",
       "3           Animator comprises trip.      1\n",
       "4        Welfare constructs hundred.      0\n",
       "..                               ...    ...\n",
       "303           Majority stops helmet.      0\n",
       "304         Beach picks involvement.      0\n",
       "305              Book realizes size.      0\n",
       "306      Landfill intersects number.      0\n",
       "307        Heat emphasizes opponent.      0\n",
       "\n",
       "[308 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pap_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6ce39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n",
      "{'input_ids': tensor([[    0, 26267, 42354,  ...,     1,     1,     1],\n",
      "        [    0, 47661, 29237,  ...,     1,     1,     1],\n",
      "        [    0, 12667,  7292,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 24751, 26558,  ...,     1,     1,     1],\n",
      "        [    0, 26902, 29238,  ...,     1,     1,     1],\n",
      "        [    0, 44644, 27995,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([308, 512])\n",
      "torch.Size([308, 512])\n",
      "308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 308\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_testset_pap = create_dataset(pap_test, tokenizer)\n",
    "hf_testset_pap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25741a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worm enter cave.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elephant toss cat.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beak tap purse.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wolf push cup.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pen etch oil.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Air peel bush.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Man pull ant.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Hand fasten crab.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Student beat man.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Cup crop pebbles.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text  label\n",
       "0      Worm enter cave.      1\n",
       "1    Elephant toss cat.      1\n",
       "2       Beak tap purse.      1\n",
       "3        Wolf push cup.      1\n",
       "4         Pen etch oil.      0\n",
       "..                  ...    ...\n",
       "302      Air peel bush.      0\n",
       "303       Man pull ant.      0\n",
       "304   Hand fasten crab.      1\n",
       "305   Student beat man.      1\n",
       "306   Cup crop pebbles.      0\n",
       "\n",
       "[307 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pep_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ae7907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "{'input_ids': tensor([[    0,   771,  8693,  ...,     1,     1,     1],\n",
      "        [    0, 28888, 44254,  ...,     1,     1,     1],\n",
      "        [    0,  9325,   677,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 21292,  1769,  ...,     1,     1,     1],\n",
      "        [    0, 43541,  1451,  ...,     1,     1,     1],\n",
      "        [    0,   347,   658,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([307, 512])\n",
      "torch.Size([307, 512])\n",
      "307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 307\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_testset_pep = create_dataset(pep_test, tokenizer)\n",
    "hf_testset_pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8a9f719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    pap: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 308\n",
       "    })\n",
       "    pep: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 307\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_testsets = DatasetDict(\n",
    "    {\n",
    "        'pap': hf_testset_pap,\n",
    "        'pep': hf_testset_pep,\n",
    "    }\n",
    ")\n",
    "hf_testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10362da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de21dc56197431cb5ab6e4988bdff70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4bf909b1ee487e8366f30ef581491c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/307 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_testsets.save_to_disk('./output/testsets_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f3a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
