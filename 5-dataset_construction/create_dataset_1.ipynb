{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303cce00",
   "metadata": {},
   "source": [
    "# Create and prepare the dataset for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f0ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4202583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/mount/studenten/arbeitsdaten-studenten1/semantic-plausibility/plausible-parrots/'\n",
    "CACHE_DIR = PATH + 'cache/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04512e7",
   "metadata": {},
   "source": [
    "## Load all the 6 data splits. Merge pap_train and pep_train, pap_dev and pep_dev, as well as pap_test and pep_test, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a57c158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/\n",
      "[]\n",
      "['et_pap_dev_wikidata.csv', 'et_pap_train_wikidata.csv', 'et_pap_test_wikidata.csv', 'et_pep_test_wikidata.csv', 'et_pep_train_wikidata.csv', 'et_pep_dev_wikidata.csv']\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['et_pap_dev_wikidata', 'et_pap_train_wikidata', 'et_pap_test_wikidata', 'et_pep_test_wikidata', 'et_pep_train_wikidata', 'et_pep_dev_wikidata'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = {}\n",
    "for root, dirs, files in os.walk('../input/'):\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            fn = file.replace('.csv', '')\n",
    "            fp = root + file\n",
    "            dataframes[fn] = pd.read_csv(fp)\n",
    "            \n",
    "print(len(dataframes))\n",
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f6471",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5727b175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_type</th>\n",
       "      <th>subject_types</th>\n",
       "      <th>object_types</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Event occurs year.</td>\n",
       "      <td>{'sen_id': 0, 'sentence': 'Event occurs year.'...</td>\n",
       "      <td>[{'wd_qid': 'Q1656682', 'wd_label': 'event', '...</td>\n",
       "      <td>[{'wd_qid': 'Q577', 'wd_label': 'year', 'descr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tortoise brings limb.</td>\n",
       "      <td>{'sen_id': 1, 'sentence': 'Tortoise brings lim...</td>\n",
       "      <td>[{'wd_qid': 'Q729', 'wd_label': 'animal', 'des...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headliner overpowers function.</td>\n",
       "      <td>{'sen_id': 2, 'sentence': 'Headliner overpower...</td>\n",
       "      <td>[{'wd_qid': 'Q151885', 'wd_label': 'concept', ...</td>\n",
       "      <td>[{'wd_qid': 'Q11348', 'wd_label': 'function', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>County receives hour.</td>\n",
       "      <td>{'sen_id': 3, 'sentence': 'County receives hou...</td>\n",
       "      <td>[{'wd_qid': 'Q15284', 'wd_label': 'municipalit...</td>\n",
       "      <td>[{'wd_qid': 'Q25235', 'wd_label': 'hour', 'des...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Traveler acknowledges recognition.</td>\n",
       "      <td>{'sen_id': 4, 'sentence': 'Traveler acknowledg...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q7302601', 'wd_label': 'recogniti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>Wool clip dust.</td>\n",
       "      <td>{'sen_id': 2444, 'sentence': 'Wool clip dust.'...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Rope hook pan.</td>\n",
       "      <td>{'sen_id': 2445, 'sentence': 'Rope hook pan.',...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>Bag contain tree.</td>\n",
       "      <td>{'sen_id': 2446, 'sentence': 'Bag contain tree...</td>\n",
       "      <td>[{'wd_qid': 'Q1323314', 'wd_label': 'bag', 'de...</td>\n",
       "      <td>[{'wd_qid': 'Q756', 'wd_label': 'plant', 'desc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>Gorilla bury leaf.</td>\n",
       "      <td>{'sen_id': 2447, 'sentence': 'Gorilla bury lea...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q33971', 'wd_label': 'leaf', 'des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>Sidewalk curb wheels.</td>\n",
       "      <td>{'sen_id': 2448, 'sentence': 'Sidewalk curb wh...</td>\n",
       "      <td>[{'wd_qid': 'Q5004679', 'wd_label': 'path', 'd...</td>\n",
       "      <td>[{'wd_qid': 'Q446', 'wd_label': 'wheel', 'desc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4911 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  \\\n",
       "0                     Event occurs year.   \n",
       "1                  Tortoise brings limb.   \n",
       "2         Headliner overpowers function.   \n",
       "3                  County receives hour.   \n",
       "4     Traveler acknowledges recognition.   \n",
       "...                                  ...   \n",
       "2444                     Wool clip dust.   \n",
       "2445                      Rope hook pan.   \n",
       "2446                   Bag contain tree.   \n",
       "2447                  Gorilla bury leaf.   \n",
       "2448               Sidewalk curb wheels.   \n",
       "\n",
       "                                             event_type  \\\n",
       "0     {'sen_id': 0, 'sentence': 'Event occurs year.'...   \n",
       "1     {'sen_id': 1, 'sentence': 'Tortoise brings lim...   \n",
       "2     {'sen_id': 2, 'sentence': 'Headliner overpower...   \n",
       "3     {'sen_id': 3, 'sentence': 'County receives hou...   \n",
       "4     {'sen_id': 4, 'sentence': 'Traveler acknowledg...   \n",
       "...                                                 ...   \n",
       "2444  {'sen_id': 2444, 'sentence': 'Wool clip dust.'...   \n",
       "2445  {'sen_id': 2445, 'sentence': 'Rope hook pan.',...   \n",
       "2446  {'sen_id': 2446, 'sentence': 'Bag contain tree...   \n",
       "2447  {'sen_id': 2447, 'sentence': 'Gorilla bury lea...   \n",
       "2448  {'sen_id': 2448, 'sentence': 'Sidewalk curb wh...   \n",
       "\n",
       "                                          subject_types  \\\n",
       "0     [{'wd_qid': 'Q1656682', 'wd_label': 'event', '...   \n",
       "1     [{'wd_qid': 'Q729', 'wd_label': 'animal', 'des...   \n",
       "2     [{'wd_qid': 'Q151885', 'wd_label': 'concept', ...   \n",
       "3     [{'wd_qid': 'Q15284', 'wd_label': 'municipalit...   \n",
       "4     [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "...                                                 ...   \n",
       "2444  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...   \n",
       "2445  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...   \n",
       "2446  [{'wd_qid': 'Q1323314', 'wd_label': 'bag', 'de...   \n",
       "2447  [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "2448  [{'wd_qid': 'Q5004679', 'wd_label': 'path', 'd...   \n",
       "\n",
       "                                           object_types  label  \n",
       "0     [{'wd_qid': 'Q577', 'wd_label': 'year', 'descr...      1  \n",
       "1     [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      1  \n",
       "2     [{'wd_qid': 'Q11348', 'wd_label': 'function', ...      1  \n",
       "3     [{'wd_qid': 'Q25235', 'wd_label': 'hour', 'des...      0  \n",
       "4     [{'wd_qid': 'Q7302601', 'wd_label': 'recogniti...      1  \n",
       "...                                                 ...    ...  \n",
       "2444  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      0  \n",
       "2445  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      1  \n",
       "2446  [{'wd_qid': 'Q756', 'wd_label': 'plant', 'desc...      0  \n",
       "2447  [{'wd_qid': 'Q33971', 'wd_label': 'leaf', 'des...      1  \n",
       "2448  [{'wd_qid': 'Q446', 'wd_label': 'wheel', 'desc...      1  \n",
       "\n",
       "[4911 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_pap_train_wikidata = dataframes['et_pap_train_wikidata']\n",
    "et_pap_train_wikidata.drop('original_label', axis=1, inplace=True)\n",
    "et_pap_train_wikidata = et_pap_train_wikidata[['text', 'event_type', 'subject_types', 'object_types', 'label']]\n",
    "\n",
    "et_pep_train_wikidata = dataframes['et_pep_train_wikidata']\n",
    "et_pep_train_wikidata = et_pep_train_wikidata[['text', 'event_type', 'subject_types', 'object_types', 'label']]\n",
    "\n",
    "train_wikidata = pd.concat([et_pap_train_wikidata, et_pep_train_wikidata])\n",
    "train_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a67196",
   "metadata": {},
   "source": [
    "### dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dba368c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_type</th>\n",
       "      <th>subject_types</th>\n",
       "      <th>object_types</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Method seizes bacterium.</td>\n",
       "      <td>{'sen_id': 0, 'sentence': 'Method seizes bacte...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q7239', 'wd_label': 'organism', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technician visits community.</td>\n",
       "      <td>{'sen_id': 1, 'sentence': 'Technician visits c...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q98929991', 'wd_label': 'place', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inclusion expands range.</td>\n",
       "      <td>{'sen_id': 2, 'sentence': 'Inclusion expands r...</td>\n",
       "      <td>[{'wd_qid': 'Q151885', 'wd_label': 'concept', ...</td>\n",
       "      <td>[{'wd_qid': 'Q11500', 'wd_label': 'area', 'des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pencil puts norm.</td>\n",
       "      <td>{'sen_id': 3, 'sentence': 'Pencil puts norm.',...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q151885', 'wd_label': 'concept', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solution musters team.</td>\n",
       "      <td>{'sen_id': 4, 'sentence': 'Solution musters te...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q16334295', 'wd_label': 'group of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Girl slide water.</td>\n",
       "      <td>{'sen_id': 301, 'sentence': 'Girl slide water....</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q283', 'wd_label': 'water', 'desc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Plant bury air.</td>\n",
       "      <td>{'sen_id': 302, 'sentence': 'Plant bury air.',...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q7391292', 'wd_label': 'air', 'de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Hand roll plane.</td>\n",
       "      <td>{'sen_id': 303, 'sentence': 'Hand roll plane.'...</td>\n",
       "      <td>[{'wd_qid': 'Q33767', 'wd_label': 'hand', 'des...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Cup spill water.</td>\n",
       "      <td>{'sen_id': 304, 'sentence': 'Cup spill water.'...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>[{'wd_qid': 'Q11435', 'wd_label': 'liquid', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Scissors tear paper.</td>\n",
       "      <td>{'sen_id': 305, 'sentence': 'Scissors tear pap...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  \\\n",
       "0        Method seizes bacterium.   \n",
       "1    Technician visits community.   \n",
       "2        Inclusion expands range.   \n",
       "3               Pencil puts norm.   \n",
       "4          Solution musters team.   \n",
       "..                            ...   \n",
       "301             Girl slide water.   \n",
       "302               Plant bury air.   \n",
       "303              Hand roll plane.   \n",
       "304              Cup spill water.   \n",
       "305          Scissors tear paper.   \n",
       "\n",
       "                                            event_type  \\\n",
       "0    {'sen_id': 0, 'sentence': 'Method seizes bacte...   \n",
       "1    {'sen_id': 1, 'sentence': 'Technician visits c...   \n",
       "2    {'sen_id': 2, 'sentence': 'Inclusion expands r...   \n",
       "3    {'sen_id': 3, 'sentence': 'Pencil puts norm.',...   \n",
       "4    {'sen_id': 4, 'sentence': 'Solution musters te...   \n",
       "..                                                 ...   \n",
       "301  {'sen_id': 301, 'sentence': 'Girl slide water....   \n",
       "302  {'sen_id': 302, 'sentence': 'Plant bury air.',...   \n",
       "303  {'sen_id': 303, 'sentence': 'Hand roll plane.'...   \n",
       "304  {'sen_id': 304, 'sentence': 'Cup spill water.'...   \n",
       "305  {'sen_id': 305, 'sentence': 'Scissors tear pap...   \n",
       "\n",
       "                                         subject_types  \\\n",
       "0    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "1    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "2    [{'wd_qid': 'Q151885', 'wd_label': 'concept', ...   \n",
       "3    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "4    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "..                                                 ...   \n",
       "301  [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "302  [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "303  [{'wd_qid': 'Q33767', 'wd_label': 'hand', 'des...   \n",
       "304  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...   \n",
       "305  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...   \n",
       "\n",
       "                                          object_types  label  \n",
       "0    [{'wd_qid': 'Q7239', 'wd_label': 'organism', '...      0  \n",
       "1    [{'wd_qid': 'Q98929991', 'wd_label': 'place', ...      1  \n",
       "2    [{'wd_qid': 'Q11500', 'wd_label': 'area', 'des...      1  \n",
       "3    [{'wd_qid': 'Q151885', 'wd_label': 'concept', ...      0  \n",
       "4    [{'wd_qid': 'Q16334295', 'wd_label': 'group of...      1  \n",
       "..                                                 ...    ...  \n",
       "301  [{'wd_qid': 'Q283', 'wd_label': 'water', 'desc...      0  \n",
       "302  [{'wd_qid': 'Q7391292', 'wd_label': 'air', 'de...      0  \n",
       "303  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      0  \n",
       "304  [{'wd_qid': 'Q11435', 'wd_label': 'liquid', 'd...      1  \n",
       "305  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      1  \n",
       "\n",
       "[614 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_pap_dev_wikidata = dataframes['et_pap_dev_wikidata']\n",
    "et_pap_dev_wikidata.drop('original_label', axis=1, inplace=True)\n",
    "et_pap_dev_wikidata = et_pap_dev_wikidata[['text', 'event_type', 'subject_types', 'object_types', 'label']]\n",
    "\n",
    "et_pep_dev_wikidata = dataframes['et_pep_dev_wikidata']\n",
    "et_pep_dev_wikidata = et_pep_dev_wikidata[['text', 'event_type', 'subject_types', 'object_types', 'label']]\n",
    "\n",
    "dev_wikidata = pd.concat([et_pap_dev_wikidata, et_pep_dev_wikidata])\n",
    "dev_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356fb02",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "270f68c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_type</th>\n",
       "      <th>subject_types</th>\n",
       "      <th>object_types</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interpretation construes title.</td>\n",
       "      <td>{'sen_id': 0, 'sentence': 'Interpretation cons...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q216353', 'wd_label': 'title', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mask sustains axis.</td>\n",
       "      <td>{'sen_id': 1, 'sentence': 'Mask sustains axis....</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trader ensures strategy.</td>\n",
       "      <td>{'sen_id': 2, 'sentence': 'Trader ensures stra...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q185451', 'wd_label': 'strategy',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animator comprises trip.</td>\n",
       "      <td>{'sen_id': 3, 'sentence': 'Animator comprises ...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welfare constructs hundred.</td>\n",
       "      <td>{'sen_id': 4, 'sentence': 'Welfare constructs ...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q11563', 'wd_label': 'number', 'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Air peel bush.</td>\n",
       "      <td>{'sen_id': 302, 'sentence': 'Air peel bush.', ...</td>\n",
       "      <td>[{'wd_qid': 'Q7391292', 'wd_label': 'air', 'de...</td>\n",
       "      <td>[{'wd_qid': 'Q756', 'wd_label': 'plant', 'desc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Man pull ant.</td>\n",
       "      <td>{'sen_id': 303, 'sentence': 'Man pull ant.', '...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Hand fasten crab.</td>\n",
       "      <td>{'sen_id': 304, 'sentence': 'Hand fasten crab....</td>\n",
       "      <td>[{'wd_qid': 'Q33767', 'wd_label': 'hand', 'des...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Student beat man.</td>\n",
       "      <td>{'sen_id': 305, 'sentence': 'Student beat man....</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>[{'wd_qid': 'Q215627', 'wd_label': 'person', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Cup crop pebbles.</td>\n",
       "      <td>{'sen_id': 306, 'sentence': 'Cup crop pebbles....</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>[{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  \\\n",
       "0    Interpretation construes title.   \n",
       "1                Mask sustains axis.   \n",
       "2           Trader ensures strategy.   \n",
       "3           Animator comprises trip.   \n",
       "4        Welfare constructs hundred.   \n",
       "..                               ...   \n",
       "302                   Air peel bush.   \n",
       "303                    Man pull ant.   \n",
       "304                Hand fasten crab.   \n",
       "305                Student beat man.   \n",
       "306                Cup crop pebbles.   \n",
       "\n",
       "                                            event_type  \\\n",
       "0    {'sen_id': 0, 'sentence': 'Interpretation cons...   \n",
       "1    {'sen_id': 1, 'sentence': 'Mask sustains axis....   \n",
       "2    {'sen_id': 2, 'sentence': 'Trader ensures stra...   \n",
       "3    {'sen_id': 3, 'sentence': 'Animator comprises ...   \n",
       "4    {'sen_id': 4, 'sentence': 'Welfare constructs ...   \n",
       "..                                                 ...   \n",
       "302  {'sen_id': 302, 'sentence': 'Air peel bush.', ...   \n",
       "303  {'sen_id': 303, 'sentence': 'Man pull ant.', '...   \n",
       "304  {'sen_id': 304, 'sentence': 'Hand fasten crab....   \n",
       "305  {'sen_id': 305, 'sentence': 'Student beat man....   \n",
       "306  {'sen_id': 306, 'sentence': 'Cup crop pebbles....   \n",
       "\n",
       "                                         subject_types  \\\n",
       "0    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "1    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "2    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "3    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "4    [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "..                                                 ...   \n",
       "302  [{'wd_qid': 'Q7391292', 'wd_label': 'air', 'de...   \n",
       "303  [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "304  [{'wd_qid': 'Q33767', 'wd_label': 'hand', 'des...   \n",
       "305  [{'wd_qid': 'Q215627', 'wd_label': 'person', '...   \n",
       "306  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...   \n",
       "\n",
       "                                          object_types  label  \n",
       "0    [{'wd_qid': 'Q216353', 'wd_label': 'title', 'd...      1  \n",
       "1    [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      0  \n",
       "2    [{'wd_qid': 'Q185451', 'wd_label': 'strategy',...      1  \n",
       "3    [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      1  \n",
       "4    [{'wd_qid': 'Q11563', 'wd_label': 'number', 'd...      0  \n",
       "..                                                 ...    ...  \n",
       "302  [{'wd_qid': 'Q756', 'wd_label': 'plant', 'desc...      0  \n",
       "303  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      0  \n",
       "304  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      1  \n",
       "305  [{'wd_qid': 'Q215627', 'wd_label': 'person', '...      1  \n",
       "306  [{'wd_qid': 'Q35120', 'wd_label': 'entity', 'd...      0  \n",
       "\n",
       "[615 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_pap_test_wikidata = dataframes['et_pap_test_wikidata']\n",
    "et_pap_test_wikidata.drop('original_label', axis=1, inplace=True)\n",
    "et_pap_test_wikidata = et_pap_test_wikidata[['text', 'event_type', 'subject_types', 'object_types', 'label']]\n",
    "\n",
    "et_pep_test_wikidata = dataframes['et_pep_test_wikidata']\n",
    "et_pep_test_wikidata = et_pep_test_wikidata[['text', 'event_type', 'subject_types', 'object_types', 'label']]\n",
    "\n",
    "test_wikidata = pd.concat([et_pap_test_wikidata, et_pep_test_wikidata])\n",
    "test_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3821f5b",
   "metadata": {},
   "source": [
    "## Load tokenizer and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9313fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli', cache_dir=CACHE_DIR)\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large-mnli', cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f22e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e24450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>',\n",
       " 'additional_special_tokens': ['[ETYPE]',\n",
       "  '[/STYPE]',\n",
       "  '[OTYPE]',\n",
       "  '[/OTYPE]',\n",
       "  '[EVT]',\n",
       "  '[DEF]',\n",
       "  '[/EVT]',\n",
       "  '[STYPE]',\n",
       "  '[/ETYPE]',\n",
       "  '[/DEF]']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = {\n",
    "    'additional_special_tokens': ['[STYPE]',\n",
    "                                  '[/STYPE]',\n",
    "                                  '[ETYPE]',\n",
    "                                  '[/ETYPE]',\n",
    "                                  '[OTYPE]',\n",
    "                                  '[/OTYPE]',\n",
    "                                  '[DEF]',\n",
    "                                  '[/DEF]',\n",
    "                                  '[EVT]',\n",
    "                                  '[/EVT]',\n",
    "                                 ]\n",
    "}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9e3852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta-base': 512,\n",
       " 'roberta-large': 512,\n",
       " 'roberta-large-mnli': 512,\n",
       " 'distilroberta-base': 512,\n",
       " 'roberta-base-openai-detector': 512,\n",
       " 'roberta-large-openai-detector': 512}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf498e7",
   "metadata": {},
   "source": [
    "## Create dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fefe2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_SENT = \"\"\"\n",
    "[EVT]{sent}[/EVT]\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_SUBJ_BASIC = \"\"\"\n",
    "The subject \"{subj}\" has type [STYPE]{stype}[/STYPE], which means [DEF]{stype_desc}[/DEF].\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_SUBJ_EXTEND = \"\"\"\n",
    "It can also have type [STYPE]{stype}[/STYPE], which means [DEF]{stype_desc}[/DEF].\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_SUBJ_UNK = \"\"\"\n",
    "The subject \"{subj}\" has an unknown type.\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_VERB = \"\"\"\n",
    "The verb \"{verb}\" has type [ETYPE]{etype}[/ETYPE], which means [DEF]{etype_desc}[/DEF].\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_VERB_UNK = \"\"\"\n",
    "The verb \"{verb}\" has an unknown type.\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_OBJ_BASIC = \"\"\"\n",
    "The object \"{obj}\" has type [OTYPE]{otype}[/OTYPE], which means [DEF]{otype_desc}[/DEF].\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_OBJ_EXTEND = \"\"\"\n",
    "It can also have type [OTYPE]{otype}[/OTYPE], which means [DEF]{otype_desc}[/DEF].\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_OBJ_UNK = \"\"\"\n",
    "The object \"{obj}\" has an unknown type.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0943c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def populate_templates(sent, subj, verb, obj, stype, etype, otype, stype_desc, etype_desc, otype_desc):\n",
    "#     \"\"\"\n",
    "#     Populate the templates using the information extracted from an item (i.e. a row) in the dataframe.\n",
    "    \n",
    "#     Args:\n",
    "#         sent:str         The sentence expressing the event.\n",
    "#         subj:str         The subject of the sentence.\n",
    "#         verb:str         The verb of the sentence.\n",
    "#         obj:str          The object of the sentence.\n",
    "#         stype:str        The subject type name.\n",
    "#         etype:str        The verb type (i.e. event type) name.\n",
    "#         otype:str        The object type name.\n",
    "#         stype_desc:str   The subject type description.\n",
    "#         etype_desc:str   The verb type (i.e. event type) description.\n",
    "#         otype_desc:str   The object type description.\n",
    "        \n",
    "#     Return:\n",
    "#         prompt:str       A prompt constructed from the templates and the item.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     prompt = TEMPLATE_SENT.replace('<sent>', sent)\n",
    "#     prompt += TEMPLATE_SUBJ_BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc837d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_templates(row:pd.core.series.Series):\n",
    "    \n",
    "    sentence = row['text']\n",
    "    svo = sentence.split(\" \")\n",
    "    s = svo[0]\n",
    "    v = svo[1]\n",
    "    o = svo[2][:-1]\n",
    "    #print(f\"s:{s}, v:{v}, o:{o}\")\n",
    "    \n",
    "    # Initialize the prompt with the event sentence.\n",
    "    prompt = TEMPLATE_SENT.format(sent=sentence)\n",
    "    \n",
    "    # Populate subject type.\n",
    "    if len(row['subject_types']) > 0:\n",
    "        for i, st in enumerate(row['subject_types']):\n",
    "            subject_type_name = st['wd_label']\n",
    "            subject_type_desc = st['description']\n",
    "            if i < 1:\n",
    "                prompt += TEMPLATE_SUBJ_BASIC.format(subj=s, stype=subject_type_name, stype_desc=subject_type_desc)\n",
    "            else:\n",
    "                prompt += TEMPLATE_SUBJ_EXTEND.format(subj=s, stype=subject_type_name, stype_desc=subject_type_desc)\n",
    "    else:\n",
    "        prompt += TEMPLATE_SUBJ_UNK\n",
    "    \n",
    "    # Populate event type.\n",
    "    event_type = row['event_type']\n",
    "    if len(event_type['predicted_mentions']) > 0:\n",
    "        event_trigger = row['event_type']['predicted_mentions'][0]['trigger_words']\n",
    "        if v == event_trigger:\n",
    "            event_type = row['event_type']['predicted_mentions'][0]['event_type']\n",
    "            event_type_name = event_type['name']\n",
    "            event_type_desc = event_type['description']\n",
    "            prompt += TEMPLATE_VERB.format(verb=v, etype=event_type_name, etype_desc=event_type_desc)\n",
    "        else:\n",
    "            prompt += TEMPLATE_VERB_UNK.format(verb=v)\n",
    "    else:\n",
    "        prompt += TEMPLATE_VERB_UNK.format(verb=v)\n",
    "        \n",
    "    \n",
    "        \n",
    "    # Populate object type.\n",
    "    if len(row['object_types']) > 0:\n",
    "        for i, ot in enumerate(row['object_types']):\n",
    "            object_type_name = ot['wd_label']\n",
    "            object_type_desc = ot['description']\n",
    "            if i < 1:\n",
    "                prompt += TEMPLATE_OBJ_BASIC.format(obj=o, otype=object_type_name, otype_desc=object_type_desc)\n",
    "            else:\n",
    "                prompt += TEMPLATE_OBJ_EXTEND.format(obj=o, otype=object_type_name, otype_desc=object_type_desc)\n",
    "    else:\n",
    "        prompt += TEMPLATE_OBJ_UNK\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4623a359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(data_df:pd.core.frame.DataFrame, tokenizer):\n",
    "\n",
    "    prompts = []\n",
    "    for i, row in tqdm(data_df.iterrows()):\n",
    "        row['event_type'] = ast.literal_eval(row['event_type'])\n",
    "        row['subject_types'] = ast.literal_eval(row['subject_types'])\n",
    "        row['object_types'] = ast.literal_eval(row['object_types'])\n",
    "\n",
    "        prompt = populate_templates(row)\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    ids = list(range(len(prompts)))\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = data_df['label'].tolist()\n",
    "#     for i, prompt in tqdm(enumerate(prompts)):\n",
    "#         encoded_inputs = tokenizer(\n",
    "#             prompt,\n",
    "#             return_tensors='pt',\n",
    "#             padding=True, \n",
    "#             truncation=True, \n",
    "#             max_length=tokenizer.max_len_single_sentence, \n",
    "#             add_special_tokens=True)\n",
    "# #         print(encoded_inputs)\n",
    "#         input_ids.append(encoded_inputs['input_ids'].squeeze())\n",
    "#         attention_mask.append(encoded_inputs['attention_mask'].squeeze())\n",
    "#         ids.append(i)\n",
    "    encoded_inputs = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors='pt',\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    print(len(ids))\n",
    "    print(encoded_inputs)\n",
    "    print(encoded_inputs['input_ids'].shape)\n",
    "    print(encoded_inputs['attention_mask'].shape)\n",
    "    print(len(labels))\n",
    "        \n",
    "    dataset_dict = {\n",
    "        'id': ids, \n",
    "        'input_ids': encoded_inputs['input_ids'], \n",
    "        'attention_mask': encoded_inputs['attention_mask'], \n",
    "        'labels': labels\n",
    "    }\n",
    "        \n",
    "    hf_dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcab72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4911it [00:00, 5304.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4911\n",
      "{'input_ids': tensor([[    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([4911, 512])\n",
      "torch.Size([4911, 512])\n",
      "4911\n",
      "4911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 4911\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_train = create_dataset(train_wikidata, tokenizer)\n",
    "print(len(hf_dataset_train))\n",
    "hf_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d84e904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "614it [00:00, 5505.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "{'input_ids': tensor([[    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([614, 512])\n",
      "torch.Size([614, 512])\n",
      "614\n",
      "614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 614\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_dev = create_dataset(dev_wikidata, tokenizer)\n",
    "print(len(hf_dataset_dev))\n",
    "hf_dataset_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d338ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [00:00, 5410.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n",
      "{'input_ids': tensor([[    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1],\n",
      "        [    0, 50118, 50269,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "torch.Size([615, 512])\n",
      "torch.Size([615, 512])\n",
      "615\n",
      "615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 615\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_test = create_dataset(test_wikidata, tokenizer)\n",
    "print(len(hf_dataset_test))\n",
    "hf_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e6401b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4911\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 614\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 615\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_train_dev_test = DatasetDict(\n",
    "    {\n",
    "        'train': hf_dataset_train,\n",
    "        'dev': hf_dataset_dev,\n",
    "        'test': hf_dataset_test\n",
    "    }\n",
    ")\n",
    "hf_dataset_train_dev_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e6a5d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909c048b89e94d5c9ef1b3e0c14b6ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1383501aad714ec097290a50bb7f8016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a07b7e6ee774057a67ced12c3137fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset_train_dev_test.save_to_disk('./output/dataset_5-2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e64817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ff39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f1438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23931196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de81e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
